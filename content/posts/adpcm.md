+++
banner = ""
categories = ["Multimedia", "Audio", "Computer Sience", "Mathematics"]
date = 2019-11-21T20:52:27+09:00
description = "ADPCM (適応差分パルス変調) の概要"
images = []
menu = ""
tags = ["ADPCM", "PCM"]
title = "ADPCM"
+++

# PCM

アナログ信号である音 (媒体の振動) をコンピュータで処理するためには, 0 と 1 のみの情報, つまり, デジタル信号に変換する必要があります. その処理は, 以下の 3 つのステップになります.

1. サンプリング
1. 量子化
1. 符号化

サンプリングや量子化に共通することは, 連続した信号を離散信号に変換することです. コンピューター (の内部) では連続した値や無限大となる値を扱うことが不可能だからです. また, 離散信号に変換することで, データサイズを圧縮することもできます. このような, 音データの圧縮方法を **PCM** (Pulse Code Modulation) と呼びます.

![サンプリング・量子化・符号化](https://user-images.githubusercontent.com/4006693/69397180-9782b500-0d28-11ea-96da-567c51fac38a.gif)

音信号は, 2 つの連続した物理量 (次元) をもっています. **時間**と**振幅**です. サンプリングと量子化は, これら2つの連続した物理量を離散信号に変換する処理となります.

## サンプリング (標本化)

**サンプリング** (**標本化**) は, 時間を離散した値に変換する処理です. 離散信号, すなわち, とびとびの値をとっていくためには, その間隔を決定するパラメータが必要になります. それが, **サンプリング周期** (**標本化周期**) です.

サンプリング周期の逆数となるパラメータは, **サンプリング周波数** (**標本化周波数**) です. 簡単に解説すれば, サンプリング周波数は, 1 sec のあいだに, いくつのサンプル (離散点) をとるかということを意味しています. 例えば, サンプリング周波数が 48000 の場合, 1 sec のあいだに 48000 サンプル (離散点) をとることになります.

![サンプリング周波数](https://user-images.githubusercontent.com/4006693/69397201-ab2e1b80-0d28-11ea-9d2f-a2da19e0ce56.png)

サンプリングでは重要な定理があります. それは, **サンプリング周波数の 1 / 2 より大きい周波数は元のアナログ信号に復元できないという定理**です. この定理は, **サンプリング定理** (標本化定理, シャノンの定理) と呼ばれます. また, サンプリング周波数の 1 / 2 の周波数は**ナイキスト周波数**と呼ばれます.

サンプリングの精度を高くするほど, すなわち, サンプリング周波数を高くするほど元のアナログ信号に対してより忠実度の高いディジタル信号に変換可能となります. 一方で, データサイズはサンプリング周波数に比例して大きくなってしまいます.

![サンプリング周波数と音質](https://user-images.githubusercontent.com/4006693/69397217-b97c3780-0d28-11ea-83ad-45a9355adf0b.png)

サンプリング周波数の具体例として, 音楽 CD は 44.1 kHz に設定されています. この理由は, 人間の聴覚が知覚可能な周波数はおよそ 20 kHz であることを考慮して, そのうえでサンプリング定理を適用しているからです. さらに音質の高いものだと 96 kHz に設定されている音楽 CD (データ) もあります. しかし, 電話では, 8 kHz に設定されています. 音声の場合は, 多少音質が損なわれても相手の音声を聴きとることが可能なこと, 楽器音ほど高い周波数成分が含まれないこと, リアルタイムに通信するので可能な限りデータサイズを減らす必要があることなどが理由としてあげられます.

## 量子化

**量子化** は, 振幅を離散した値に変換する処理です. サンプリングと同じく, とびとびの値をとっていくためには, その間隔を決定づけるパラメータが必要になります. それが, **量子化ビット** (**量子化精度**) です.

サンプリングされたアナログ信号は時間軸方向は, 離散化されていますが, 振幅軸の方向は, まだ連続したままです. 量子化では, 量子化ビットで指定された精度にしたがって, 振幅を整数値に丸める処理を実行します. 例えば, 量子化ビットが 2 bit の場合, 4 つのステップの値 ($2^{2}=4$) のいずれかに, 3 bit の場合, 8 つのステップの値 ($2^{3}=8$) のいずれかに振幅が丸められます.

![量子化ビット](https://user-images.githubusercontent.com/4006693/69397240-d31d7f00-0d28-11ea-8292-013be30cb8aa.png)

サンプリングの精度と同様に, 量子化の精度を高くするほど, すなわち, 量子化ビットを大きくするほど元のアナログ信号に対してより忠実度の高いディジタル信号に変換可能となりますが, データサイズは量子化ビットに比例して大きくなってしまいます.

![量子化ビットと音質](https://user-images.githubusercontent.com/4006693/69397261-e3cdf500-0d28-11ea-8732-9c7344fb6004.png)

## 符号化

量子化した (整数値に丸めた) 振幅を 2 進数に変換すると, コンピューターの内部で処理することが可能なデジタル信号となります.

# log-PCM

音信号は振幅の小さい部分と振幅の大きい部分がありますが, 振幅の小さい部分の方が発生する確率は圧倒的に高くなります. したがって, 振幅の小さい部分は細かく, 振幅の大きい部分は粗く量子化することによって, データサイズをおさえつつも, 音質の劣化を知覚的に防止することができます.

このような PCM を **log-PCM** (Logarithmic PCM) と呼びます. log-PCM は主に固定電話に適用される方式です. log-PCM では, 入力音の振幅を対数変換し, 変換後の音に対して一様な量子化を実行します.

log-PCM では, 圧縮された音を元に戻すために, 圧縮の逆の手順となる復号の処理が必要になります (これを, 圧縮に対して**伸張**と呼ぶこともあります). log-PCM の対数特製の決め方には自由度があるので, 伸張の方法も各方式によって異なります.

代表的な対数特性としては, **A 法則** (A-law) と **$\mu$ 法則** ($\mu$-low) があります.

# DPCM (デルタ PCM)

サンプリング周期が短い場合, 音の隣接するサンプル間の変化は小さくなります. そこで, 隣接するサンプルの差分をとれば, 元の音よりも信号の散らばり (分散) の程度を小さくでき, 割り当てるビット数を少なくできます. このように, 差分信号を量子化する方式を **DPCM** (Differential PCM), または, **デルタ PCM** と呼びます.

# 適応量子化

音が急激に変化する部分と, 緩やかに変化する部分では, 差分信号であっても 2 つの差は大きくなるので, このような信号に対して, 固定の量子化幅を利用することは効果的ではありません.

そこで, 信号の大きさに合わせて量子化幅を変更し, 圧縮効率を改善する方式が, **適応量子化** (Adaptive Quantization) です.

# ADPCM

音信号は多くの場合, 過去の信号と密接に関係しているので, 過去の値から現在の値をある程度予測することができます. 予測値と現在の音との差分を**予測誤差** (Prediction Error) と呼び, DPCM よりもさらに小さい分散をもちます.

したがって, 予測誤差を量子化の対象として, さらに, 適応量子化を導入すれば, 非常に高い圧縮効率を得ることができます. このような, 予測と量子化の 2 つの適応制御をそなえた方式を **ADPCM** (Adaptive Differential PCM), **適応差分パルス変調**と呼びます.

ADPCM は, WAVE ファイルにも利用されています. ADPCM は, エンコーダ / デコーダが複雑というデメリットはもちますが, 少ないビット数で高い音質を保持できるというメリットがあります.

以下のセクションでは, 国際電気通信連合 ITU で定められている, G.726 方式の ADPCM について解説します.

## ADPCM エンコーダ

適応量子化器は, 入力信号 $s\_{1}(n)$ から, 予測信号 $s\_{e}(n)$ を減算した, 予測誤差を量子化します. 予測信号 $s\_{e}(n)$ は過去の入力信号 (実際は, 再合成信号) を参照して生成されます. 量子化された予測誤差が, ADPCM 信号 $I(n)$ として送信されます.

![ADPCM エンコーダ](https://user-images.githubusercontent.com/4006693/69674052-0b351100-10df-11ea-9ba7-b6e68b03d6a0.png)

ADPCM 信号生成の後処理として, 逆量子化によって予測誤差を復元します. そして, 予測ごさと予測信号を加算することで入力信号を再合成 ($s\_{r}(n)$) します. 再合成信号 $s\_{r}(n)$ を利用して, 次の自国の入力信号を予測します. 予測信号 $s\_{e}(n)$ は, 前回の予測誤差が 0 に近づくように予測器の係数を更新したあとに計算されます. 逆量子化以降の処理は, $I(n)$ だけから実行できることが特徴です. ADPCM ではこの特徴を, そのままでデコーダに活用しています. まとめると,

1. 現在の観測信号に対する予測値を生成する
1. 観測信号から予測値を減算して予測誤差を得る
1. 予測ごさを量子化する (ADPCM 信号)
1. 予測誤差と予測値を加算して, 観測信号を再合成する
1. 予測誤差を参照して, 量子化器と予測器を更新する

## ADPCM デコーダ

ADPCM 信号の逆量子化以降の処理は, エンコーダと同じです. 予測器の更新結果も, 観測された予測ごさを 0 に近づけることを目的とするので, エンコーダと同じ更新結果が得られます. 問題は, 予測信号の初期値をどのように設定するかですが, G.726 では, ある定数を指定しています. デコーダの最終出力は, 予測誤差と予測信号を加算した再合成信号です.

![ADPCM デコーダ](https://user-images.githubusercontent.com/4006693/69674125-2a33a300-10df-11ea-8db1-84d6c1f261d7.png)

1. 現在の観測信号に対する予測値を生成する
1. 予測誤差である ADPCM 信号を受信する
1. 予測ごさと予測値を加算して, 観測信号を再合成する
1. 予測ごさを参照して, 量子化器と予測器を更新する

# リファレンス

- [ディジタル音声&画像の圧縮/伸長/加工技術: 大容量化するマルチメディア・データを転送・保存・活用するために (ディジタル信号処理シリーズ)](https://www.amazon.co.jp/%E3%83%87%E3%82%A3%E3%82%B8%E3%82%BF%E3%83%AB%E9%9F%B3%E5%A3%B0-%E7%94%BB%E5%83%8F%E3%81%AE%E5%9C%A7%E7%B8%AE-%E5%8A%A0%E5%B7%A5%E6%8A%80%E8%A1%93-%E5%A4%A7%E5%AE%B9%E9%87%8F%E5%8C%96%E3%81%99%E3%82%8B%E3%83%9E%E3%83%AB%E3%83%81%E3%83%A1%E3%83%87%E3%82%A3%E3%82%A2%E3%83%BB%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E8%BB%A2%E9%80%81%E3%83%BB%E4%BF%9D%E5%AD%98%E3%83%BB%E6%B4%BB%E7%94%A8%E3%81%99%E3%82%8B%E3%81%9F%E3%82%81%E3%81%AB-%E3%83%87%E3%82%A3%E3%82%B8%E3%82%BF%E3%83%AB%E4%BF%A1%E5%8F%B7%E5%87%A6%E7%90%86%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA/dp/4789831450)
